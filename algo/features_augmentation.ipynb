{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Normalize\n",
    "import random\n",
    "from PIL import Image\n",
    "import wandb\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Required crop size (224, 224) is larger than input image size (180, 180)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 89\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAugmentation complete.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m dataset_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/workspaces/AICoinXpert/algo/webscraping/data/selected_coins_above20\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 89\u001b[0m augment_images(dataset_dir\u001b[39m=\u001b[39;49mdataset_dir, output_dir\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/workspaces/AICoinXpert/algo/webscraping/data/pool_20_above_filtered\u001b[39;49m\u001b[39m\"\u001b[39;49m, num_transformations\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[2], line 81\u001b[0m, in \u001b[0;36maugment_images\u001b[0;34m(dataset_dir, output_dir, num_transformations)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39m# Apply random transformations\u001b[39;00m\n\u001b[1;32m     80\u001b[0m random_transformations \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39msample(augment_transform, random\u001b[39m.\u001b[39mrandint(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(augment_transform)))\n\u001b[0;32m---> 81\u001b[0m augmented_image \u001b[39m=\u001b[39m apply_random_transformations(image, random_transformations)\n\u001b[1;32m     83\u001b[0m \u001b[39m# Save the augmented image\u001b[39;00m\n\u001b[1;32m     84\u001b[0m augmented_image\u001b[39m.\u001b[39msave(augmented_filepath)\n",
      "Cell \u001b[0;32mIn[2], line 17\u001b[0m, in \u001b[0;36mapply_random_transformations\u001b[0;34m(image, random_transforms)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Applies random transformations to the input image.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39m    PIL.Image: The transformed image.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m transform \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose(random_transforms)\n\u001b[0;32m---> 17\u001b[0m \u001b[39mreturn\u001b[39;00m transform(image)\n",
      "File \u001b[0;32m/workspaces/AICoinXpert/.venv/lib/python3.11/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[1;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/workspaces/AICoinXpert/.venv/lib/python3.11/site-packages/torchvision/transforms/transforms.py:582\u001b[0m, in \u001b[0;36mRandomChoice.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs):\n\u001b[1;32m    581\u001b[0m     t \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mchoices(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms, weights\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp)[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 582\u001b[0m     \u001b[39mreturn\u001b[39;00m t(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m/workspaces/AICoinXpert/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/workspaces/AICoinXpert/.venv/lib/python3.11/site-packages/torchvision/transforms/transforms.py:688\u001b[0m, in \u001b[0;36mRandomCrop.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    685\u001b[0m     padding \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize[\u001b[39m0\u001b[39m] \u001b[39m-\u001b[39m height]\n\u001b[1;32m    686\u001b[0m     img \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mpad(img, padding, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfill, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode)\n\u001b[0;32m--> 688\u001b[0m i, j, h, w \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_params(img, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msize)\n\u001b[1;32m    690\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mcrop(img, i, j, h, w)\n",
      "File \u001b[0;32m/workspaces/AICoinXpert/.venv/lib/python3.11/site-packages/torchvision/transforms/transforms.py:647\u001b[0m, in \u001b[0;36mRandomCrop.get_params\u001b[0;34m(img, output_size)\u001b[0m\n\u001b[1;32m    644\u001b[0m th, tw \u001b[39m=\u001b[39m output_size\n\u001b[1;32m    646\u001b[0m \u001b[39mif\u001b[39;00m h \u001b[39m<\u001b[39m th \u001b[39mor\u001b[39;00m w \u001b[39m<\u001b[39m tw:\n\u001b[0;32m--> 647\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRequired crop size \u001b[39m\u001b[39m{\u001b[39;00m(th,\u001b[39m \u001b[39mtw)\u001b[39m}\u001b[39;00m\u001b[39m is larger than input image size \u001b[39m\u001b[39m{\u001b[39;00m(h,\u001b[39m \u001b[39mw)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    649\u001b[0m \u001b[39mif\u001b[39;00m w \u001b[39m==\u001b[39m tw \u001b[39mand\u001b[39;00m h \u001b[39m==\u001b[39m th:\n\u001b[1;32m    650\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, h, w\n",
      "\u001b[0;31mValueError\u001b[0m: Required crop size (224, 224) is larger than input image size (180, 180)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "def apply_random_transformations(image, random_transforms):\n",
    "    \"\"\"Applies random transformations to the input image.\n",
    "\n",
    "    Args:\n",
    "        image (PIL.Image): The input image.\n",
    "        random_transforms (list): List of random transformations to apply.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image: The transformed image.\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose(random_transforms)\n",
    "    return transform(image)\n",
    "\n",
    "def augment_images(dataset_dir: str, output_dir: str, num_transformations=100):\n",
    "    \"\"\"Function to augment images in the dataset and save them in class-specific folders.\n",
    "\n",
    "    Args:\n",
    "        dataset_dir (str): The directory containing the images to augment.\n",
    "        output_dir (str): The directory to save the augmented images to.\n",
    "        num_transformations (int, optional): The number of images to transform for each image. Defaults to 100.\n",
    "    \"\"\"\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Additional transformations for augmentation\n",
    "    additional_transforms = [\n",
    "        transforms.RandomApply([\n",
    "            transforms.Grayscale(num_output_channels=3),  # Convert to grayscale (3 channels)\n",
    "        ], p=0.5),\n",
    "    ]\n",
    "    \n",
    "    # Define the transformations for augmentation\n",
    "    augment_transform = [\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomChoice([\n",
    "            transforms.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0)),  # Zoom in\n",
    "            transforms.RandomCrop(size=(224, 224), padding=20),  # Zoom out\n",
    "        ]),\n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(\n",
    "                brightness=random.uniform(0.1, 0.5),\n",
    "                contrast=random.uniform(0.1, 0.5),\n",
    "                saturation=random.uniform(0.1, 0.5),\n",
    "                hue=random.uniform(0.1, 0.5),\n",
    "            ),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.RandomRotation(degrees=random.uniform(10, 20)),\n",
    "        ], p=0.5),\n",
    "        *additional_transforms,\n",
    "    ]\n",
    "\n",
    "    # Walk through the directory tree (including subdirectories)\n",
    "    for root, _, filenames in os.walk(dataset_dir):\n",
    "        for filename in filenames:\n",
    "            # Extract the coin name from the filename\n",
    "            coin_name = os.path.splitext(filename)[0]\n",
    "\n",
    "            # Create a folder for the coin name in the output directory if it doesn't exist\n",
    "            coin_folder = os.path.join(output_dir, os.path.relpath(root, dataset_dir), coin_name)\n",
    "            os.makedirs(coin_folder, exist_ok=True)\n",
    "\n",
    "            # Load the image\n",
    "            image_path = os.path.join(root, filename)\n",
    "            with Image.open(image_path).convert(\"RGB\") as image:\n",
    "                # Apply random transformations to the original image and save augmented images\n",
    "                for j in range(num_transformations):\n",
    "                    # Generate a new filename for the augmented image with the label included\n",
    "                    augmented_filename = f\"{coin_name}_augmented_{j}.jpg\"\n",
    "\n",
    "                    # Determine the output path for the augmented image\n",
    "                    augmented_filepath = os.path.join(coin_folder, augmented_filename)\n",
    "\n",
    "                    # Apply random transformations\n",
    "                    random_transformations = random.sample(augment_transform, random.randint(1, len(augment_transform)))\n",
    "                    augmented_image = apply_random_transformations(image, random_transformations)\n",
    "\n",
    "                    # Save the augmented image\n",
    "                    augmented_image.save(augmented_filepath)\n",
    "\n",
    "    print(\"Augmentation complete.\")\n",
    "\n",
    "dataset_dir = \"/workspaces/AICoinXpert/algo/webscraping/data/selected_coins_above20\"\n",
    "augment_images(dataset_dir=dataset_dir, output_dir=\"/workspaces/AICoinXpert/algo/webscraping/data/pool_20_above_filtered\", num_transformations=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting and organizing images complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from typing import List\n",
    "\n",
    "def split_images(main_directory: str, output_directory: str, train_ratio: float = 0.7, test_ratio: float = 0.2):\n",
    "    \"\"\"\n",
    "    Split the images from main_directory into train, test, and eval sets and organize them in output_directory.\n",
    "\n",
    "    Args:\n",
    "        main_directory (str): The directory containing the class folders.\n",
    "        output_directory (str): The directory to save the train, test, and eval folders.\n",
    "        train_ratio (float, optional): The ratio of images to include in the train set. Defaults to 0.7.\n",
    "        test_ratio (float, optional): The ratio of images to include in the test set. Defaults to 0.2.\n",
    "    \"\"\"\n",
    "    # Create train, test, and eval folders in the output directory\n",
    "    train_dir = os.path.join(output_directory, \"train\")\n",
    "    test_dir = os.path.join(output_directory, \"test\")\n",
    "    eval_dir = os.path.join(output_directory, \"eval\")\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    os.makedirs(eval_dir, exist_ok=True)\n",
    "\n",
    "    # Get a list of class folders in the main directory\n",
    "    class_folders = [folder for folder in os.listdir(main_directory) if os.path.isdir(os.path.join(main_directory, folder))]\n",
    "\n",
    "    # Iterate through each class folder\n",
    "    for class_folder in class_folders:\n",
    "        class_directory = os.path.join(main_directory, class_folder)\n",
    "\n",
    "        # Get the list of image filenames in the class folder\n",
    "        image_filenames = os.listdir(class_directory)\n",
    "\n",
    "        # Shuffle the image filenames\n",
    "        random.shuffle(image_filenames)\n",
    "\n",
    "        # Calculate the number of images for each split\n",
    "        total_images = len(image_filenames)\n",
    "        num_train = int(total_images * train_ratio)\n",
    "        num_test = int(total_images * test_ratio)\n",
    "        num_eval = total_images - num_train - num_test\n",
    "\n",
    "        # Create the output directories for the current class in train, test, and eval folders\n",
    "        train_class_dir = os.path.join(train_dir, class_folder)\n",
    "        test_class_dir = os.path.join(test_dir, class_folder)\n",
    "        eval_class_dir = os.path.join(eval_dir, class_folder)\n",
    "        os.makedirs(train_class_dir, exist_ok=True)\n",
    "        os.makedirs(test_class_dir, exist_ok=True)\n",
    "        os.makedirs(eval_class_dir, exist_ok=True)\n",
    "\n",
    "        # Move images to the respective folders based on the split ratio\n",
    "        for i, filename in enumerate(image_filenames):\n",
    "            source_filepath = os.path.join(class_directory, filename)\n",
    "\n",
    "            if i < num_train:\n",
    "                destination_filepath = os.path.join(train_class_dir, filename)\n",
    "            elif i < num_train + num_test:\n",
    "                destination_filepath = os.path.join(test_class_dir, filename)\n",
    "            else:\n",
    "                destination_filepath = os.path.join(eval_class_dir, filename)\n",
    "\n",
    "            shutil.move(source_filepath, destination_filepath)\n",
    "\n",
    "    print(\"Splitting and organizing images complete.\")\n",
    "\n",
    "# Usage example:\n",
    "split_images(main_directory=\"/workspaces/AICoinXpert/algo/webscraping/data/pool_20_above_filtered\", output_directory=\"/workspaces/AICoinXpert/algo/webscraping/data/organized_images_20_above_filtered\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train folders: 200, Train images: 69800\n",
      "Test folders: 199, Test images: 19800\n",
      "Eval folders: 200, Eval images: 10400\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_folders_and_images(directory):\n",
    "    folder_count = 0\n",
    "    image_count = 0\n",
    "\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        folder_count += len(dirs)\n",
    "        image_count += len(files)\n",
    "\n",
    "    return folder_count, image_count\n",
    "\n",
    "# Example usage:\n",
    "output_directory = \"/workspaces/AICoinXpert/algo/webscraping/data/organized_images_20_above_filtered\"\n",
    "train_folder_count, train_image_count = count_folders_and_images(os.path.join(output_directory, \"train\"))\n",
    "test_folder_count, test_image_count = count_folders_and_images(os.path.join(output_directory, \"test\"))\n",
    "eval_folder_count, eval_image_count = count_folders_and_images(os.path.join(output_directory, \"eval\"))\n",
    "\n",
    "print(f\"Train folders: {train_folder_count}, Train images: {train_image_count}\")\n",
    "print(f\"Test folders: {test_folder_count}, Test images: {test_image_count}\")\n",
    "print(f\"Eval folders: {eval_folder_count}, Eval images: {eval_image_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "def reduce_dataset(input_dir, output_dir, percentage):\n",
    "    # Create the output directories if they don't exist\n",
    "    os.makedirs(os.path.join(output_dir, 'train'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'test'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'eval'), exist_ok=True)\n",
    "\n",
    "    # Iterate through the input directories\n",
    "    for split_dir in os.listdir(input_dir):\n",
    "        # Create the output directory for the current split\n",
    "        os.makedirs(os.path.join(output_dir, split_dir), exist_ok=True)\n",
    "\n",
    "        # Iterate through the subdirectories in the current split\n",
    "        for class_dir in os.listdir(os.path.join(input_dir, split_dir)):\n",
    "            # Create the output directory for the current class\n",
    "            os.makedirs(os.path.join(output_dir, split_dir, class_dir), exist_ok=True)\n",
    "\n",
    "            # Get the list of image filenames in the current class directory\n",
    "            image_filenames = os.listdir(os.path.join(input_dir, split_dir, class_dir))\n",
    "\n",
    "            # Calculate the number of images to select based on the percentage\n",
    "            num_images = int(len(image_filenames) * percentage)\n",
    "\n",
    "            # Randomly select the specified number of images\n",
    "            selected_images = random.sample(image_filenames, num_images)\n",
    "\n",
    "            # Copy the selected images to the output directory for the current class\n",
    "            for filename in selected_images:\n",
    "                src_path = os.path.join(input_dir, split_dir, class_dir, filename)\n",
    "                dst_path = os.path.join(output_dir, split_dir, class_dir, filename)\n",
    "                shutil.copy(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_dataset(\"/workspaces/AICoinXpert/algo/webscraping/data/organized_images_20_above_filtered\", \"/workspaces/AICoinXpert/algo/webscraping/data/\", 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
