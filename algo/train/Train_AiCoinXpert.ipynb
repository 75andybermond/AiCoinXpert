{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JWzW9GfwWAR",
        "outputId": "ea7998c1-e6bf-4733-9c0b-64fdece9cab5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/abermond/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# Continue with regular imports\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import os\n",
        "from torch import nn\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchsummary import summary\n",
        "from sklearn.metrics import precision_score, confusion_matrix\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "# Start the timer\n",
        "from timeit import default_timer as timer\n",
        "import engine, helper_functions\n",
        "# from clearml import Task\n",
        "# task = Task.init(project_name=\"exploration/AiCoinXpert\", task_name=\"task0.0.1\")\n",
        "# task.execute_remotely(queue_name=\"kube-cuda11.0_high_priority_01\", exit_process=True)\n",
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    # print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n",
        "    # !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    # !mv pytorch-deep-learning/going_modular .\n",
        "    # !rm -rf pytorch-deep-learning\n",
        "    from going_modular.going_modular import data_setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GEDwmaULirEs",
        "outputId": "b007073e-3c05-4d8f-88dc-62d92d82159b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGVBii6_v9Al",
        "outputId": "4f9cc857-a8b0-423b-90f3-8cfc4027aaca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# In dev container :\n",
        "\n",
        "# train_dir =\"/workspaces/AICoinXpert/algo/webscraping/data/organized_images_20_above_filtered/train/\"\n",
        "# test_dir = \"/workspaces/AICoinXpert/algo/webscraping/data/organized_images_20_above_filtered/test/\"\n",
        "# eval_dir = \"/workspaces/AICoinXpert/algo/webscraping/data/organized_images_20_above_filtered/eval/\"\n",
        "\n",
        "# Working without in dev container use the following paths :\n",
        "\n",
        "train_dir = \"/home/abermond/Desktop/workspaces/AICoinXpert/algo/webscraping/data/organized_images_20_above_filtered/train\"\n",
        "test_dir = \"/home/abermond/Desktop/workspaces/AICoinXpert/algo/webscraping/data/organized_images_20_above_filtered/test/\"\n",
        "eval_dir = \"/home/abermond/Desktop/workspaces/AICoinXpert/algo/webscraping/data/organized_images_20_above_filtered/eval/\"\n",
        "\n",
        "# Setup Workers\n",
        "NUM_WORKERS = torch.cuda.device_count() if torch.cuda.is_available() else os.cpu_count()\n",
        "NUM_WORKERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xuZiTMbXvv7E"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(198, 69300)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a transforms pipeline manually (required for torchvision < 0.13)\n",
        "manual_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n",
        "    transforms.ToTensor(), # 2. Turn image values to between 0 & 1\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n",
        "                         std=[0.229, 0.224, 0.225]) # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n",
        "])\n",
        "\n",
        "# Create the training and testing datasets\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=manual_transforms)\n",
        "test_dataset = datasets.ImageFolder(test_dir, transform=manual_transforms)\n",
        "eval_dataset = datasets.ImageFolder(eval_dir, transform=manual_transforms)\n",
        "\n",
        "# Create training DataLoader with a full batch\n",
        "#train_dataloader = data_setup.DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=True, num_workers=NUM_WORKERS)\n",
        "#test_dataloader = data_setup.DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False, num_workers=NUM_WORKERS)\n",
        "#eval_dataloader = data_setup.DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False, num_workers=NUM_WORKERS)\n",
        "\n",
        "# Create training DataLoader with a mini batch\n",
        "train_dataloader = data_setup.DataLoader(train_dataset, batch_size=25, shuffle=True, num_workers=NUM_WORKERS)\n",
        "test_dataloader = data_setup.DataLoader(test_dataset, batch_size=25, shuffle=False, num_workers=NUM_WORKERS)\n",
        "eval_dataloader = data_setup.DataLoader(eval_dataset, batch_size=25, shuffle=False, num_workers=NUM_WORKERS)\n",
        "\n",
        "\n",
        "# Get a list of class names\n",
        "class_names = train_dataset.classes  # Assuming both train_dataset and test_dataset have the same class names\n",
        "\n",
        "# Move to GPU if available\n",
        "#train_dataloader = train_dataloader.to(device)\n",
        "#test_dataloader = test_dataloader.to(device)\n",
        "\n",
        "# Create training and testing DataLoaders as well as get a list of class names\n",
        "#train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                               #test_dir=test_dir,\n",
        "                                                                               #transform=manual_transforms, # resize, convert images to between 0 & 1 and normalize them\n",
        "                                                                               #batch_size=25)\n",
        "len(class_names), len(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "56a7fj9axruR"
      },
      "outputs": [],
      "source": [
        "# Get a set of pretrained model weights\n",
        "weights = torchvision.models.EfficientNet_B7_Weights.DEFAULT # .DEFAULT = best available weights from pretraining on ImageNet\n",
        "# weights\n",
        "# print(len(model.layers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lvxY57JUxrxC"
      },
      "outputs": [],
      "source": [
        "#weights = torchvision.models.DenseNet121_Weights.DEFAULT # .DEFAULT = best available weights\n",
        "model = torchvision.models.efficientnet_b7(weights=weights).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Pn2rfgJkxrzG"
      },
      "outputs": [],
      "source": [
        "# Freeze all base layers in the \"features\" section of the model (the feature extractor) by setting requires_grad=False\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TMNX7J3ayfZn"
      },
      "outputs": [],
      "source": [
        "# Print a summary using torchinfo (uncomment for actual output)\n",
        "model_summary = summary(model=model,\n",
        "        input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\"\n",
        "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3SILSQj9Pb2b"
      },
      "outputs": [],
      "source": [
        "#model_summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QvsT4rfZxr1Z"
      },
      "outputs": [],
      "source": [
        "# Get the length of class_names (one output unit for each class)\n",
        "output_shape = len(class_names)\n",
        "\n",
        "# Recreate the classifier layer and seed it to the target device\n",
        "model.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p=0.2, inplace=True),\n",
        "    torch.nn.Linear(in_features=2560,\n",
        "                    out_features=output_shape, # same number of output units as our number of classes\n",
        "                    bias=True)).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7VxW7XgMxr4F"
      },
      "outputs": [],
      "source": [
        "# Define loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1.0)\n",
        "\n",
        "param_grid = {\n",
        "    \"learning_rate\": [0.001, 0.01, 0.1],\n",
        "    \"batch_size\": [64, 128, 256],\n",
        "    \"weight_decay\": [0.0, 0.4, 1]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NnIbP_yaxr6W"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 | Params: {'batch_size': 64, 'learning_rate': 0.001, 'weight_decay': 0.0}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 | Training Loss: 1.6384 | Training Accuracy: 0.7095\n",
            "Epoch: 1 | Testing Loss: 1.1247 | Testing Accuracy: 0.7840\n",
            "Epoch: 1 | Evaluation Loss: 1.1240 | Evaluation Accuracy: 0.7830\n",
            "Best params: {'batch_size': 64, 'learning_rate': 0.001, 'weight_decay': 0.0}\n",
            "Epoch: 1 | Params: {'batch_size': 64, 'learning_rate': 0.001, 'weight_decay': 0.4}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1 [31:49<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/abermond/Desktop/workspaces/AICoinXpert/algo/train/Train_AiCoinXpert.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/abermond/Desktop/workspaces/AICoinXpert/algo/train/Train_AiCoinXpert.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m start_time \u001b[39m=\u001b[39m timer()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/abermond/Desktop/workspaces/AICoinXpert/algo/train/Train_AiCoinXpert.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Setup training and save the results\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/abermond/Desktop/workspaces/AICoinXpert/algo/train/Train_AiCoinXpert.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m results \u001b[39m=\u001b[39m engine\u001b[39m.\u001b[39;49mtrain(model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/abermond/Desktop/workspaces/AICoinXpert/algo/train/Train_AiCoinXpert.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                        train_dataloader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/abermond/Desktop/workspaces/AICoinXpert/algo/train/Train_AiCoinXpert.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                        test_dataloader\u001b[39m=\u001b[39;49mtest_dataloader,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/abermond/Desktop/workspaces/AICoinXpert/algo/train/Train_AiCoinXpert.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m                        eval_dataloader\u001b[39m=\u001b[39;49meval_dataloader,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/abermond/Desktop/workspaces/AICoinXpert/algo/train/Train_AiCoinXpert.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                        optimizer\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49moptim\u001b[39m.\u001b[39;49mAdam(model\u001b[39m.\u001b[39;49mparameters()),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/abermond/Desktop/workspaces/AICoinXpert/algo/train/Train_AiCoinXpert.ipynb#X14sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                        loss_fn\u001b[39m=\u001b[39;49mloss_fn,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/abermond/Desktop/workspaces/AICoinXpert/algo/train/Train_AiCoinXpert.ipynb#X14sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                        epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/abermond/Desktop/workspaces/AICoinXpert/algo/train/Train_AiCoinXpert.ipynb#X14sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                        device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/abermond/Desktop/workspaces/AICoinXpert/algo/train/Train_AiCoinXpert.ipynb#X14sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                        patience\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/abermond/Desktop/workspaces/AICoinXpert/algo/train/Train_AiCoinXpert.ipynb#X14sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                        param_grid\u001b[39m=\u001b[39;49mparam_grid)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/abermond/Desktop/workspaces/AICoinXpert/algo/train/Train_AiCoinXpert.ipynb#X14sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# End the timer and print out how long it took\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/abermond/Desktop/workspaces/AICoinXpert/algo/train/Train_AiCoinXpert.ipynb#X14sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m end_time \u001b[39m=\u001b[39m timer()\n",
            "File \u001b[0;32m~/Desktop/workspaces/AICoinXpert/algo/train/engine.py:249\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, test_dataloader, eval_dataloader, optimizer, loss_fn, epochs, device, patience, param_grid)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m params\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    247\u001b[0m     \u001b[39msetattr\u001b[39m(model, key, value)\n\u001b[0;32m--> 249\u001b[0m train_loss, train_acc \u001b[39m=\u001b[39m train_step(\n\u001b[1;32m    250\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    251\u001b[0m     dataloader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[1;32m    252\u001b[0m     loss_fn\u001b[39m=\u001b[39;49mloss_fn,\n\u001b[1;32m    253\u001b[0m     optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m    254\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    255\u001b[0m )\n\u001b[1;32m    257\u001b[0m \u001b[39m# Print training loss and accuracy\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[1;32m    259\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m | \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining Loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m | \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mtrain_acc\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m )\n",
            "File \u001b[0;32m~/Desktop/workspaces/AICoinXpert/algo/train/engine.py:49\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, dataloader, loss_fn, optimizer, device)\u001b[0m\n\u001b[1;32m     46\u001b[0m X, y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     48\u001b[0m \u001b[39m# 1. Forward pass\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m y_pred \u001b[39m=\u001b[39m model(X)\n\u001b[1;32m     51\u001b[0m \u001b[39m# 2. Calculate  and accumulate loss\u001b[39;00m\n\u001b[1;32m     52\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(y_pred, y)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/models/efficientnet.py:343\u001b[0m, in \u001b[0;36mEfficientNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 343\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/models/efficientnet.py:333\u001b[0m, in \u001b[0;36mEfficientNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_impl\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 333\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures(x)\n\u001b[1;32m    335\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)\n\u001b[1;32m    336\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/models/efficientnet.py:164\u001b[0m, in \u001b[0;36mMBConv.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 164\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblock(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_res_connect:\n\u001b[1;32m    166\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstochastic_depth(result)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Set the random seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Start the timer\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "# Setup training and save the results\n",
        "results = engine.train(model=model,\n",
        "                       train_dataloader=train_dataloader,\n",
        "                       test_dataloader=test_dataloader,\n",
        "                       eval_dataloader=eval_dataloader,\n",
        "                       optimizer=torch.optim.Adam(model.parameters()),\n",
        "                       loss_fn=loss_fn,\n",
        "                       epochs=1,\n",
        "                       device=device,\n",
        "                       patience=0,\n",
        "                       param_grid=param_grid)\n",
        "\n",
        "# End the timer and print out how long it took\n",
        "end_time = timer()\n",
        "print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AacNWT0JL_7H"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "\n",
        "now = datetime.now()\n",
        "model_save_path = f\"/home/abermond/Desktop/workspaces/AICoinXpert/algo/train_{now.strftime('%m_%d_%Y_%H_%M')}.pth\"\n",
        "torch.save(model.state_dict(), model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "F4eZ7CkCxr8i",
        "outputId": "72bf33aa-eb2f-436c-d469-f0e88f781e00"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Get the plot_loss_curves() function from helper_functions.py, download the file if we don't have it\n",
        "#try:\n",
        "from helper_functions import plot_loss_curves, get_classification_report, get_confusion_matrix\n",
        "    \n",
        "# except:\n",
        "#     print(\"[INFO] Couldn't find helper_functions.py, downloading...\")\n",
        "#     with open(\"helper_functions.py\", \"wb\") as f:\n",
        "#         import requests\n",
        "#         request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "#         f.write(request.content)\n",
        "#     from helper_functions import plot_loss_curves\n",
        "\n",
        "# Plot the loss curves of our model\n",
        "plot_loss_curves(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation metrics including (classification report, confusion matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "YWfivbWvd7oP"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/abermond/Desktop/workspaces/AICoinXpert/algo/train/Train_AiCoinXpert.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/abermond/Desktop/workspaces/AICoinXpert/algo/train/Train_AiCoinXpert.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_classification_report \u001b[39m=\u001b[39m get_classification_report(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/abermond/Desktop/workspaces/AICoinXpert/algo/train/Train_AiCoinXpert.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     model, test_dataloader, device, class_names)\n",
            "File \u001b[0;32m~/Desktop/workspaces/AICoinXpert/algo/train/helper_functions.py:316\u001b[0m, in \u001b[0;36mget_classification_report\u001b[0;34m(model, dataloader, device, class_names)\u001b[0m\n\u001b[1;32m    314\u001b[0m y_true, y_pred \u001b[39m=\u001b[39m [], []\n\u001b[1;32m    315\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39minference_mode():\n\u001b[0;32m--> 316\u001b[0m     \u001b[39mfor\u001b[39;00m _, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[1;32m    317\u001b[0m         X, y \u001b[39m=\u001b[39m data  \u001b[39m# If your dataloader returns a tuple of (X, y)\u001b[39;00m\n\u001b[1;32m    318\u001b[0m         X, y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39mto(device)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1295\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1133\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
            "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    106\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 107\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    108\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    109\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
            "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
            "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    425\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
            "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
            "File \u001b[0;32m/usr/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_classification_report = get_classification_report(\n",
        "    model, test_dataloader, device, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# save to a text file the classification report\n",
        "with open(\n",
        "    f\"/home/abermond/Desktop/workspaces/AICoinXpert/algo/test_class_report_{now.strftime('%m_%d_%Y_%H_%M')}.json\",\n",
        "    \"w\",\n",
        ") as f:\n",
        "    json.dump(train_classification_report, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path_test_report = \"/home/abermond/Desktop/workspaces/AICoinXpert/algo/test_class_report_11_08_2023_15_48_classification_report.json\"\n",
        "file_path_train_report = \"/home/abermond/Desktop/workspaces/AICoinXpert/algo/train_class_report_11_08_2023_15_48_classification_report.json\"\n",
        "file_path_eval_report = \"/home/abermond/Desktop/workspaces/AICoinXpert/algo/eval_class_report_11_08_2023_15_48_classification_report.json\"\n",
        "\n",
        "print(\"train_classification_report :\")\n",
        "generate_report(file_path_train_report)\n",
        "\n",
        "print(\"test_classification_report :\")\n",
        "generate_report(file_path_test_report)\n",
        "\n",
        "print(\"eval_classification_report :\")\n",
        "generate_report(file_path_eval_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_confusion_matrix = get_confusion_matrix(\n",
        "    model, train_dataloader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm):\n",
        "    fig, ax = plt.subplots()\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", ax=ax, cmap=\"Blues\", cbar=False)\n",
        "    ax.set(xlabel=\"Predicted\", ylabel=\"True\", title=\"Confusion matrix\")\n",
        "    plt.yticks(rotation=0)\n",
        "\n",
        "\n",
        "# usage\n",
        "plot_confusion_matrix(train_confusion_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fgQ3174uyU4"
      },
      "source": [
        "## Add more monitoring of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "id": "XSYbBoV81316",
        "outputId": "d0228f07-c9b6-4133-e3f0-fa0426dd1ed8"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules.activation import LogSoftmax\n",
        "from __future__ import division, print_function\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Optional\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import wandb\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "# Define the ModelName enum\n",
        "class ModelName:\n",
        "    \"\"\"ModelName enum class that contains the available pre-trained models by their names.\"\"\"\n",
        "\n",
        "    DENSENET201 = \"densenet201\"\n",
        "    RESNET50 = \"resnet50\"\n",
        "    VGG16 = \"vgg16\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class CustomDataset:\n",
        "    \"\"\"Initializes the CustomDataset object that will contain the train, test, and val datasets.\n",
        "\n",
        "    Args:\n",
        "        train_dir (str): Train dataset directory\n",
        "        test_dir (str): Test dataset directory\n",
        "        val_dir (str): Validation dataset directory\n",
        "        batch_size (int): Batch size is the number of training examples utilized in one iteration\n",
        "        shuffle (bool): Whether to shuffle the data or not. Default is True.\n",
        "    \"\"\"\n",
        "\n",
        "    train_dir: str\n",
        "    test_dir: str\n",
        "    val_dir: str\n",
        "    batch_size: int\n",
        "    shuffle: bool = True\n",
        "    train_dataloader: Optional[DataLoader] = None\n",
        "    test_dataloader: Optional[DataLoader] = None\n",
        "    val_dataloader: Optional[DataLoader] = None\n",
        "\n",
        "\n",
        "\n",
        "    def __post_init__(self):\n",
        "        # Define manual transformations\n",
        "        self.manual_transforms = transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize((224, 224)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(\n",
        "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "        # Load the dataset\n",
        "        self._create_folder()\n",
        "        self._load_dataset(self.shuffle)\n",
        "\n",
        "    def _create_folder(self):\n",
        "        \"\"\"\n",
        "        Load the data and apply the manual transformations\n",
        "        \"\"\"\n",
        "        self.train_dataset = ImageFolder(\n",
        "            root=self.train_dir, transform=self.manual_transforms\n",
        "        )\n",
        "        self.test_dataset = ImageFolder(\n",
        "            root=self.test_dir, transform=self.manual_transforms\n",
        "        )\n",
        "        self.val_dataset = ImageFolder(\n",
        "            root=self.val_dir, transform=self.manual_transforms\n",
        "        )\n",
        "        self.class_names = self.train_dataset.classes\n",
        "        self.len_class_names = len(self.class_names)\n",
        "\n",
        "    def _load_dataset(self, shuffle):\n",
        "        \"\"\"\n",
        "        Load the data into train, test, and validation dataloaders\n",
        "\n",
        "        Args:\n",
        "            shuffle (bool): Apply shuffling to the data or not\n",
        "        \"\"\"\n",
        "        self.train_dataloader = DataLoader(\n",
        "            self.train_dataset, batch_size=self.batch_size, shuffle=shuffle\n",
        "        )\n",
        "        self.test_dataloader = DataLoader(\n",
        "            self.test_dataset, batch_size=self.batch_size, shuffle=shuffle\n",
        "        )\n",
        "        self.val_dataloader = DataLoader(\n",
        "            self.val_dataset, batch_size=self.batch_size, shuffle=False\n",
        "        )\n",
        "\n",
        "\n",
        "class Model:\n",
        "    \"\"\"Model class that will contain the pre-trained model, loss function, and optimizer.\"\"\"\n",
        "\n",
        "    AVAILABLE_MODELS = [ModelName.DENSENET201, ModelName.RESNET50, ModelName.VGG16]\n",
        "\n",
        "    def __init__(self, model_name: ModelName, custom_dataset: CustomDataset):\n",
        "        \"\"\"Initializes the Model name choosen and the training dataset.\n",
        "\n",
        "        Args:\n",
        "            model_name (ModelName): Model name to be used for training\n",
        "            custom_dataset (CustomDataset): CustomDataset object that contains the train/test/val\n",
        "        \"\"\"\n",
        "        if model_name not in self.AVAILABLE_MODELS:\n",
        "            raise ValueError(\n",
        "                f\"Invalid model name '{model_name}'. Available models: {', '.join(self.AVAILABLE_MODELS)}\"\n",
        "            )\n",
        "\n",
        "        # Load the specified pre-trained model\n",
        "        model_dict = {\n",
        "            ModelName.DENSENET201: models.densenet201(pretrained=True),\n",
        "            ModelName.RESNET50: models.resnet50(pretrained=True),\n",
        "            ModelName.VGG16: models.vgg16(pretrained=True),\n",
        "        }\n",
        "\n",
        "        if model_name not in model_dict:\n",
        "            raise ValueError(\n",
        "                f\"Invalid model name '{model_name}'. Available models: {', '.join(model_dict.keys())}\"\n",
        "            )\n",
        "\n",
        "        # Get the pre-trained model\n",
        "        model = model_dict[model_name]\n",
        "\n",
        "        # Freeze model parameters\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        torch.cuda.manual_seed(42)\n",
        "\n",
        "        # Recreate the classifier layer and seed it to the target device\n",
        "        classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.2, inplace=True),\n",
        "            nn.Linear(\n",
        "                in_features=1920,\n",
        "                out_features=custom_dataset.len_class_names,  # same number of output units as our number of classes\n",
        "                bias=True,\n",
        "            ),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        ).to(DEVICE)\n",
        "\n",
        "        # Replace the classifier in the model\n",
        "        model.classifier = classifier\n",
        "\n",
        "        # Move the model to the target device\n",
        "        model.to(DEVICE)\n",
        "\n",
        "        # Define Optimizer and Loss Function\n",
        "        loss_func = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "        # Move the loss function to the target device\n",
        "        loss_func.to(DEVICE)\n",
        "\n",
        "        # Store the model and related components as attributes of the class\n",
        "        self.model = model\n",
        "        self.loss_func = loss_func\n",
        "        self.optimizer = optimizer\n",
        "        self.custom_dataset = custom_dataset\n",
        "\n",
        "\n",
        "class Train:\n",
        "    \"\"\"Train class that will contain the model, train dataloader, epochs, project name, and tag.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: Model,\n",
        "        train_dataloader: DataLoader,\n",
        "        test_dataloader: DataLoader,\n",
        "        epochs: int,\n",
        "        project: str,\n",
        "        tag: str,\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.train_dataloader = train_dataloader\n",
        "        self.test_dataloader = test_dataloader\n",
        "        self.epochs = epochs\n",
        "        self.project = project\n",
        "        self.tag = tag\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_precision(predicted, targets) -> float:\n",
        "        \"\"\"Calculate the precision of the model.\n",
        "\n",
        "        Args:\n",
        "            predicted (Tensor): Predicted values\n",
        "            targets (Tensor): Target values\n",
        "\n",
        "        Returns:\n",
        "            float: Precision of the model\n",
        "        \"\"\"\n",
        "        true_positives = torch.sum((predicted == 1) & (targets == 1)).item()\n",
        "        false_positives = torch.sum((predicted == 1) & (targets == 0)).item()\n",
        "\n",
        "        if (true_positives + false_positives) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        precision = true_positives / (true_positives + false_positives)\n",
        "        return precision\n",
        "\n",
        "    def evaluate(self, model, dataloader, loss_func, device):\n",
        "        \"\"\"Evaluate the model.\n",
        "\n",
        "        Args:\n",
        "            model (Model): Model to be evaluated\n",
        "            dataloader (DataLoader): DataLoader to be used for evaluation\n",
        "            loss_func (LossFunction): Loss function to be used for evaluation\n",
        "            device (str): Device to be used for evaluation\n",
        "\n",
        "        Returns:\n",
        "            average_loss (float): Average loss of the model\n",
        "            accuracy (float): Accuracy of the model\n",
        "        \"\"\"\n",
        "        model.eval()\n",
        "        total_loss = 0.0\n",
        "        total_correct = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in dataloader:\n",
        "                inputs = inputs.to(device)\n",
        "                targets = targets.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = loss_func(outputs, targets)\n",
        "\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total_correct += (predicted == targets).sum().item()\n",
        "                total_samples += targets.size(0)\n",
        "\n",
        "        average_loss = total_loss / len(dataloader)\n",
        "        accuracy = 100.0 * total_correct / total_samples\n",
        "\n",
        "        return average_loss, accuracy\n",
        "\n",
        "    def train_model(self, patience=2):\n",
        "        \"\"\"Train the model.\n",
        "\n",
        "        Args:\n",
        "            patience (int, optional): Number of epochs to wait if the loss is not improving\n",
        "        \"\"\"\n",
        "        # Initialize Wandb run\n",
        "        wandb.init(\n",
        "            project=self.project,\n",
        "            tags=[self.tag],\n",
        "            config={\n",
        "                \"epochs\": self.epochs,\n",
        "                \"batch_size\": self.train_dataloader.batch_size,\n",
        "                \"lr\": 0.001,\n",
        "                \"dropout\": 0.2,\n",
        "            },\n",
        "        )\n",
        "\n",
        "        start_time = time.time()\n",
        "        best_loss = float(\"inf\")\n",
        "        counter = 0\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            # Training code here\n",
        "            self.model.model.train()\n",
        "            train_loss = 0.0\n",
        "            train_correct = 0\n",
        "            train_total = 0\n",
        "            train_loss_total = 0.0\n",
        "\n",
        "            for batch_idx ,(train_inputs, train_targets) in enumerate(\n",
        "                self.train_dataloader\n",
        "            ):\n",
        "                train_inputs = train_inputs.to(DEVICE)\n",
        "                train_targets = train_targets.to(DEVICE)\n",
        "\n",
        "                self.model.optimizer.zero_grad()\n",
        "\n",
        "                train_outputs = self.model.model(train_inputs)\n",
        "                train_loss = self.model.loss_func(train_outputs, train_targets)\n",
        "                train_loss.backward()\n",
        "                self.model.optimizer.step()\n",
        "\n",
        "\n",
        "                train_loss_total += train_loss.item()\n",
        "\n",
        "                _, train_predicted = train_outputs.max(1)\n",
        "                train_total += train_targets.size(0)\n",
        "                train_correct += train_predicted.eq(train_targets).sum().item()\n",
        "\n",
        "            train_accuracy = 100.0 * train_correct / train_total\n",
        "            train_loss = train_loss_total / len(self.train_dataloader)\n",
        "\n",
        "            train_precision = self.calculate_precision(train_predicted, train_targets)\n",
        "\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"epoch\": epoch,\n",
        "                    \"train_loss\": train_loss,\n",
        "                    \"train_accuracy\": train_accuracy,\n",
        "                    \"train_precision\": train_precision,\n",
        "                }\n",
        "            )\n",
        "\n",
        "            # Test code here\n",
        "            test_loss, test_accuracy = self.evaluate(\n",
        "                self.model.model,\n",
        "                self.test_dataloader,\n",
        "                self.model.loss_func,\n",
        "                DEVICE,\n",
        "            )\n",
        "\n",
        "            eval_loss, eval_accuracy = self.evaluate(\n",
        "                self.model.model, self.test_dataloader, self.model.loss_func, DEVICE\n",
        "            )\n",
        "\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"epochs\": epoch,\n",
        "                    \"test_loss\": test_loss,\n",
        "                    \"test_accuracy\": test_accuracy,\n",
        "                    \"eval_loss\": eval_loss,\n",
        "                    \"eval_accuracy\": eval_accuracy,\n",
        "                },\n",
        "            )\n",
        "\n",
        "            self.log_confusion_matrix(self.model.model, self.test_dataloader)\n",
        "\n",
        "            if test_loss < best_loss:\n",
        "                best_loss = test_loss\n",
        "                counter = 0\n",
        "                # Save the best model\n",
        "                timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "                torch.save(self.model.model.state_dict(), f\"best_model_{timestamp}.pth\")\n",
        "            else:\n",
        "                counter += 1\n",
        "                if counter >= patience:\n",
        "                    break\n",
        "\n",
        "        # End the timer and print out how long it took\n",
        "        end_time = time.time()\n",
        "        print(f\"[INFO] Total training time: {end_time - start_time:.3f} seconds\")\n",
        "\n",
        "        # Finish wandb run\n",
        "        wandb.finish()\n",
        "\n",
        "    def log_confusion_matrix(self, model, dataloader):\n",
        "        \"\"\"Calculate and log the confusion matrix.\n",
        "\n",
        "        Args:\n",
        "            model (Model): Model to be evaluated\n",
        "            dataloader (DataLoader): DataLoader to be used for evaluation\n",
        "        \"\"\"\n",
        "        model.eval()\n",
        "        all_predictions = []\n",
        "        all_targets = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in dataloader:\n",
        "                inputs = inputs.to(DEVICE)\n",
        "                targets = targets.to(DEVICE)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                all_predictions.extend(predicted.cpu().numpy())\n",
        "                all_targets.extend(targets.cpu().numpy())\n",
        "\n",
        "        cm = confusion_matrix(all_targets, all_predictions)\n",
        "        class_names = self.model.custom_dataset.class_names  # Access the class names from the CustomDataset through the Model\n",
        "        wandb.log({\"confusion_matrix\": wandb.plot.confusion_matrix(probs=None, y_true=all_targets, preds=all_predictions, class_names=class_names)})\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Initialize the CustomDataset object\n",
        "    data = CustomDataset(\n",
        "        train_dir=\"/content/drive/MyDrive/organized_images_above_20/train/\",\n",
        "        test_dir=\"/content/drive/MyDrive/organized_images_above_20/test/\",\n",
        "        val_dir=\"/content/drive/MyDrive/organized_images_above_20/eval/\",\n",
        "        batch_size=19800,\n",
        "    )\n",
        "    # Instantiate the model with the dataset prepared\n",
        "    model = Model(ModelName.DENSENET201, data)\n",
        "    # Train the model\n",
        "    training_step = Train(\n",
        "        model,\n",
        "        data.train_dataloader,\n",
        "        data.test_dataloader,\n",
        "        epochs=1,\n",
        "        project=\"Dense\",\n",
        "        tag=\"pool_split_80_percent_filtered\",\n",
        "    )\n",
        "    training_step.train_model()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 379,
          "referenced_widgets": [
            "61e8ee911a65453c91f100ccfd820b05",
            "aeb801f815b2494296f9de9088f08a3e",
            "b5c6bbcc537b4e53bf91f7ef954dea66",
            "9ffb8692b58346c8a97c96043880a02b",
            "8fb9256c87624f8fa57dfcd5366fa333",
            "f070025c6632403aaeae91015ac1cad1",
            "d7695d2ffa3e4f2cbced56bda5c351b1",
            "4f4fe1b28d0e4d80b81cb8572e31468b"
          ]
        },
        "id": "N-LE3ZonWpFJ",
        "outputId": "2f5dc64a-3ff5-4fa6-e7e5-ccf4ca35050a"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Optional\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import wandb\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class CustomDataset:\n",
        "    train_dir: str\n",
        "    test_dir: str\n",
        "    val_dir: str\n",
        "    batch_size: int\n",
        "    shuffle: bool = True\n",
        "    train_dataloader: Optional[DataLoader] = None\n",
        "    test_dataloader: Optional[DataLoader] = None\n",
        "    val_dataloader: Optional[DataLoader] = None\n",
        "\n",
        "    def __post_init__(self):\n",
        "        self.manual_transforms = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "        self._create_folder()\n",
        "        self._load_dataset(self.shuffle)\n",
        "\n",
        "    def _create_folder(self):\n",
        "        self.train_dataset = ImageFolder(root=self.train_dir, transform=self.manual_transforms)\n",
        "        self.test_dataset = ImageFolder(root=self.test_dir, transform=self.manual_transforms)\n",
        "        self.val_dataset = ImageFolder(root=self.val_dir, transform=self.manual_transforms)\n",
        "        self.class_names = self.train_dataset.classes\n",
        "        self.len_class_names = len(self.class_names)\n",
        "\n",
        "    def _load_dataset(self, shuffle):\n",
        "        self.train_dataloader = DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=shuffle)\n",
        "        self.test_dataloader = DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False)\n",
        "        self.val_dataloader = DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "class Model:\n",
        "    def __init__(self, custom_dataset: CustomDataset):\n",
        "        resnet19 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
        "        num_ftrs = resnet19.fc.in_features\n",
        "        resnet19.fc = nn.Linear(num_ftrs, custom_dataset.len_class_names)\n",
        "        self.model = resnet19.to(DEVICE)\n",
        "\n",
        "        self.loss_func = nn.CrossEntropyLoss()\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
        "        self.custom_dataset = custom_dataset\n",
        "\n",
        "\n",
        "class Train:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: Model,\n",
        "        train_dataloader: DataLoader,\n",
        "        test_dataloader: DataLoader,\n",
        "        epochs: int,\n",
        "        project: str,\n",
        "        tag: str,\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.train_dataloader = train_dataloader\n",
        "        self.test_dataloader = test_dataloader\n",
        "        self.epochs = epochs\n",
        "        self.project = project\n",
        "        self.tag = tag\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_precision(predicted, targets) -> float:\n",
        "        true_positives = torch.sum((predicted == 1) & (targets == 1)).item()\n",
        "        false_positives = torch.sum((predicted == 1) & (targets == 0)).item()\n",
        "\n",
        "        if (true_positives + false_positives) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        precision = true_positives / (true_positives + false_positives)\n",
        "        return precision\n",
        "\n",
        "    def evaluate(self, dataloader, loss_func, device):\n",
        "        model = self.model.model\n",
        "        model.eval()\n",
        "        total_loss = 0.0\n",
        "        total_correct = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in dataloader:\n",
        "                inputs = inputs.to(device)\n",
        "                targets = targets.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = loss_func(outputs, targets)\n",
        "\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total_correct += (predicted == targets).sum().item()\n",
        "                total_samples += targets.size(0)\n",
        "\n",
        "        average_loss = total_loss / len(dataloader)\n",
        "        accuracy = 100.0 * total_correct / total_samples\n",
        "\n",
        "        return average_loss, accuracy\n",
        "\n",
        "    def train_model(self, patience=2):\n",
        "        wandb.init(\n",
        "            project=self.project,\n",
        "            tags=[self.tag],\n",
        "            config={\n",
        "                \"epochs\": self.epochs,\n",
        "                \"batch_size\": self.train_dataloader.batch_size,\n",
        "                \"lr\": 0.001,\n",
        "                \"dropout\": 0.2,\n",
        "            },\n",
        "        )\n",
        "\n",
        "        start_time = time.time()\n",
        "        best_loss = float(\"inf\")\n",
        "        counter = 0\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            # Training code here\n",
        "            self.model.model.train()\n",
        "            train_loss = 0.0\n",
        "            train_correct = 0\n",
        "            train_total = 0\n",
        "            train_loss_total = 0.0\n",
        "\n",
        "            for batch_idx, (train_inputs, train_targets) in enumerate(self.train_dataloader):\n",
        "                train_inputs = train_inputs.to(DEVICE)\n",
        "                train_targets = train_targets.to(DEVICE)\n",
        "\n",
        "                self.model.optimizer.zero_grad()\n",
        "\n",
        "                train_outputs = self.model.model(train_inputs)\n",
        "                train_loss = self.model.loss_func(train_outputs, train_targets)\n",
        "                train_loss.backward()\n",
        "                self.model.optimizer.step()\n",
        "\n",
        "                train_loss_total += train_loss.item()\n",
        "\n",
        "                _, train_predicted = train_outputs.max(1)\n",
        "                train_total += train_targets.size(0)\n",
        "                train_correct += train_predicted.eq(train_targets).sum().item()\n",
        "\n",
        "            train_accuracy = 100.0 * train_correct / train_total\n",
        "            train_loss = train_loss_total / len(self.train_dataloader)\n",
        "\n",
        "            train_precision = self.calculate_precision(train_predicted, train_targets)\n",
        "\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"epoch\": epoch,\n",
        "                    \"train_loss\": train_loss,\n",
        "                    \"train_accuracy\": train_accuracy,\n",
        "                    \"train_precision\": train_precision,\n",
        "                }\n",
        "            )\n",
        "\n",
        "            # Test code here\n",
        "            test_loss, test_accuracy = self.evaluate(self.test_dataloader, self.model.loss_func, DEVICE)\n",
        "\n",
        "            eval_loss, eval_accuracy = self.evaluate(self.test_dataloader, self.model.loss_func, DEVICE)\n",
        "\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"epochs\": epoch,\n",
        "                    \"test_loss\": test_loss,\n",
        "                    \"test_accuracy\": test_accuracy,\n",
        "                    \"eval_loss\": eval_loss,\n",
        "                    \"eval_accuracy\": eval_accuracy,\n",
        "                },\n",
        "            )\n",
        "\n",
        "            self.log_confusion_matrix(self.model.model, self.test_dataloader)\n",
        "\n",
        "            if test_loss < best_loss:\n",
        "                best_loss = test_loss\n",
        "                counter = 0\n",
        "                timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "                torch.save(self.model.model.state_dict(), f\"best_model_{timestamp}.pth\")\n",
        "            else:\n",
        "                counter += 1\n",
        "                if counter >= patience:\n",
        "                    break\n",
        "\n",
        "        end_time = time.time()\n",
        "        print(f\"[INFO] Total training time: {end_time - start_time:.3f} seconds\")\n",
        "\n",
        "        wandb.finish()\n",
        "\n",
        "    def log_confusion_matrix(self, model, dataloader):\n",
        "        model.eval()\n",
        "        all_predictions = []\n",
        "        all_targets = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in dataloader:\n",
        "                inputs = inputs.to(DEVICE)\n",
        "                targets = targets.to(DEVICE)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                all_predictions.extend(predicted.cpu().numpy())\n",
        "                all_targets.extend(targets.cpu().numpy())\n",
        "\n",
        "        cm = confusion_matrix(all_targets, all_predictions)\n",
        "        class_names = self.model.custom_dataset.class_names\n",
        "        wandb.log({\"confusion_matrix\": wandb.plot.confusion_matrix(probs=None, y_true=all_targets, preds=all_predictions, class_names=class_names)})\n",
        "\n",
        "\n",
        "def main():\n",
        "    data = CustomDataset(\n",
        "        train_dir=\"/content/drive/MyDrive/organized_images_above_20/train/\",\n",
        "        test_dir=\"/content/drive/MyDrive/organized_images_above_20/test/\",\n",
        "        val_dir=\"/content/drive/MyDrive/organized_images_above_20/eval/\",\n",
        "        batch_size=250,\n",
        "    )\n",
        "    model = Model(data)\n",
        "    training_step = Train(\n",
        "        model,\n",
        "        data.train_dataloader,\n",
        "        data.test_dataloader,\n",
        "        epochs=5,\n",
        "        project=\"ResNet\",\n",
        "        tag=\"pool_split_80_percent_filtered\",\n",
        "    )\n",
        "    training_step.train_model()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikFhp0Z0zAm8"
      },
      "outputs": [],
      "source": [
        "!mkdir models\n",
        "!mkdir models/pytorch\n",
        "\n",
        "\n",
        "torch.save(model_trained.state_dict(), 'models/pytorch/weights.h5')\n",
        "\n",
        "\n",
        "model = models.resnet50(pretrained=False).to(device)\n",
        "model.fc = nn.Sequential(\n",
        "               nn.Linear(2048, 128),\n",
        "               nn.ReLU(inplace=True),\n",
        "               nn.Linear(128, 2)).to(device)\n",
        "model.load_state_dict(torch.load('models/pytorch/weights.h5'))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcLoduj9y9Lf"
      },
      "outputs": [],
      "source": [
        "\n",
        "### 6. Make predictions on sample test images\n",
        "\n",
        "\n",
        "validation_img_paths = [\"validation/alien/11.jpg\",\n",
        "                        \"validation/alien/22.jpg\",\n",
        "                        \"validation/predator/33.jpg\"]\n",
        "img_list = [Image.open(input_path + img_path) for img_path in validation_img_paths]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TbKzRlLy622"
      },
      "outputs": [],
      "source": [
        "validation_batch = torch.stack([data_transforms['validation'](img).to(device)\n",
        "                                for img in img_list])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moBTsYZky4TN"
      },
      "outputs": [],
      "source": [
        "pred_logits_tensor = model(validation_batch)\n",
        "pred_logits_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeZfr1OLy3fw"
      },
      "outputs": [],
      "source": [
        "\n",
        "pred_probs = F.softmax(pred_logits_tensor, dim=1).cpu().data.numpy()\n",
        "pred_probs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XIM066Fy1yF"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, len(img_list), figsize=(20, 5))\n",
        "for i, img in enumerate(img_list):\n",
        "    ax = axs[i]\n",
        "    ax.axis('off')\n",
        "    ax.set_title(\"{:.0f}% Alien, {:.0f}% Predator\".format(100*pred_probs[i,0],\n",
        "                                                            100*pred_probs[i,1]))\n",
        "    ax.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlwsZ8yxUeN8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAQSEuLJUeQh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyyLDBGJUeS8"
      },
      "outputs": [],
      "source": [
        "### Méthod Pytorch tutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7tpM4uYUeVi",
        "outputId": "38351873-4828-47a2-d4fd-9bd502096327"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "mean = np.array([0.5, 0.5, 0.5])\n",
        "std = np.array([0.25, 0.25, 0.25])\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/organized_images_above_20/'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'test']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=2,\n",
        "                                             shuffle=True, num_workers=0)\n",
        "              for x in ['train', 'test']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
        "class_names = image_datasets['train'].classes\n",
        "class_test = image_datasets['test'].classes\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(class_names)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxqeJg1ne9d3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "#declaring batch size\n",
        "batch_size = 32\n",
        "\n",
        "#applying required transformations on the dataset\n",
        "img_transforms = {\n",
        "    'train':\n",
        "    T.Compose([\n",
        "        T.Resize(size=(224,224)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
        "        ]),\n",
        "\n",
        "    'valid':\n",
        "    T.Compose([\n",
        "        T.Resize(size=(224,224)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "        ]),\n",
        "\n",
        "    'test':\n",
        "    T.Compose([\n",
        "        T.Resize(size=(224,224)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "        ]),\n",
        "     }\n",
        "\n",
        "# creating Location of data: train, validation, test\n",
        "data='/content/drive/MyDrive/organized_images_above_20/'\n",
        "\n",
        "train_path=os.path.join(data,'train')\n",
        "valid_path=os.path.join(data,'test')\n",
        "test_path=os.path.join(data,'eval')\n",
        "\n",
        "\n",
        "# creating Datasets to each of  folder created in prev\n",
        "train_file=datasets.ImageFolder(train_path,transform=img_transforms['train'])\n",
        "valid_file=datasets.ImageFolder(valid_path,transform=img_transforms['valid'])\n",
        "test_file=datasets.ImageFolder(test_path,transform=img_transforms['test'])\n",
        "\n",
        "\n",
        "#Creating loaders for the dataset\n",
        "loaders_transfer={\n",
        "    'train':torch.utils.data.DataLoader(train_file,batch_size,shuffle=True),\n",
        "    'valid':torch.utils.data.DataLoader(valid_file,batch_size,shuffle=True),\n",
        "    'test': torch.utils.data.DataLoader(test_file,batch_size,shuffle=True)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp8LM55Umk1m",
        "outputId": "5291d150-43ae-4aeb-ab3e-da6394155521"
      },
      "outputs": [],
      "source": [
        "pip install efficientnet_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQ3ejrWdfi1W"
      },
      "outputs": [],
      "source": [
        "#importing required modules\n",
        "import gdown\n",
        "import zipfile\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary\n",
        "from torchvision import datasets, transforms as T\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "import os\n",
        "import torch.optim as optim\n",
        "from PIL import ImageFile\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNuLi-HJfSHS",
        "outputId": "4fcf8b7e-56a9-4665-8056-ae3fd7d673de"
      },
      "outputs": [],
      "source": [
        "from efficientnet_pytorch import EfficientNet\n",
        "import torch.nn as nn\n",
        "\n",
        "# Load pre-trained EfficientNet model\n",
        "model_transfer = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "\n",
        "# Freeze weights of the pre-trained model\n",
        "for param in model_transfer.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Get the number of input features for the fully connected layer\n",
        "in_features = model_transfer._fc.in_features\n",
        "\n",
        "# Define Dense top layers after the convolutional layers\n",
        "num_classes = 198  # Number of classes in your dataset\n",
        "model_transfer._fc = nn.Sequential(\n",
        "    nn.BatchNorm1d(num_features=in_features),\n",
        "    nn.Linear(in_features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm1d(512),\n",
        "    nn.Linear(512, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm1d(128),\n",
        "    nn.Dropout(0.4),\n",
        "    nn.Linear(128, num_classes),  # Use num_classes as the output size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMAtEZIqf2CR"
      },
      "outputs": [],
      "source": [
        "# selecting loss function\n",
        "criterion_transfer = nn.CrossEntropyLoss()\n",
        "\n",
        "#using Adam classifier\n",
        "optimizer_transfer = optim.Adam(model_transfer.parameters(), lr=0.0005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2HMMX_5W3f2"
      },
      "outputs": [],
      "source": [
        "# Creating the function for training\n",
        "def train(n_epochs, loaders, model, optimizer, criterion, save_path):\n",
        "    \"\"\"returns trained model\"\"\"\n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf\n",
        "    trainingloss = []\n",
        "    validationloss = []\n",
        "\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        # initialize the variables to monitor training and validation loss\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "\n",
        "        ###################\n",
        "        # training the model #\n",
        "        ###################\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "\n",
        "        ######################\n",
        "        # validating the model #\n",
        "        ######################\n",
        "        model.eval()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
        "\n",
        "        train_loss = train_loss/len(train_file)\n",
        "        valid_loss = valid_loss/len(valid_file)\n",
        "\n",
        "        trainingloss.append(train_loss)\n",
        "        validationloss.append(valid_loss)\n",
        "\n",
        "        # printing training/validation statistics\n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "            epoch,\n",
        "            train_loss,\n",
        "            valid_loss\n",
        "            ))\n",
        "\n",
        "        ## saving the model if validation loss has decreased\n",
        "        if valid_loss < valid_loss_min:\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "\n",
        "            valid_loss_min = valid_loss\n",
        "\n",
        "    # return trained model\n",
        "    return model, trainingloss, validationloss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "IafvTSg-VtkM",
        "outputId": "8f57f882-c8ab-4444-a820-69aebee8d8a7"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=12):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        optimizer.zero_grad()\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'test' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best test Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "    # Freeze model parameters\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "#### Finetuning the convnet ####\n",
        "# Load a pretrained model and reset final fully connected layer.\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "\n",
        "# Here the size of each output sample is set to 2.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model.fc = nn.Linear(in_features= num_ftrs, out_features= len(class_names))\n",
        "\n",
        "\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "h0Vv31s2aWUU",
        "outputId": "cde5c8db-6f75-4d1c-e58a-bf7273324ab1"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "# StepLR Decays the learning rate of each parameter group by gamma every step_size epochs\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "# Learning rate scheduling should be applied after optimizer’s update\n",
        "# e.g., you should write your code this way:\n",
        "# for epoch in range(100):\n",
        "#     train(...)\n",
        "#     validate(...)\n",
        "#     scheduler.step()\n",
        "\n",
        "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=25)\n",
        "\n",
        "\n",
        "#### ConvNet as fixed feature extractor ####\n",
        "# Here, we need to freeze all the network except the final layer.\n",
        "# We need to set requires_grad == False to freeze the parameters so that the gradients are not computed in backward()\n",
        "model_conv = torchvision.models.resnet18(pretrained=True)\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "num_ftrs = model_conv.fc.in_features\n",
        "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as\n",
        "# opposed to before.\n",
        "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
        "\n",
        "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
        "                         exp_lr_scheduler, num_epochs=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnLGqFoqZvlz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4f4fe1b28d0e4d80b81cb8572e31468b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "61e8ee911a65453c91f100ccfd820b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aeb801f815b2494296f9de9088f08a3e",
              "IPY_MODEL_b5c6bbcc537b4e53bf91f7ef954dea66"
            ],
            "layout": "IPY_MODEL_9ffb8692b58346c8a97c96043880a02b"
          }
        },
        "8fb9256c87624f8fa57dfcd5366fa333": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ffb8692b58346c8a97c96043880a02b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeb801f815b2494296f9de9088f08a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fb9256c87624f8fa57dfcd5366fa333",
            "placeholder": "​",
            "style": "IPY_MODEL_f070025c6632403aaeae91015ac1cad1",
            "value": "0.001 MB of 0.010 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "b5c6bbcc537b4e53bf91f7ef954dea66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7695d2ffa3e4f2cbced56bda5c351b1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f4fe1b28d0e4d80b81cb8572e31468b",
            "value": 0.11075471698113208
          }
        },
        "d7695d2ffa3e4f2cbced56bda5c351b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f070025c6632403aaeae91015ac1cad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
